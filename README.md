# Credit Card Fraud Detection: A Comprehensive Machine Learning Project

A complete end-to-end machine learning pipeline for credit card fraud detection, demonstrating best practices for handling imbalanced datasets and building production-ready classification models.

## üìã Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Dataset](#dataset)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Methodology](#methodology)
- [Results](#results)
- [Key Findings](#key-findings)
- [Requirements](#requirements)
- [Contributing](#contributing)
- [License](#license)

## üîç Overview

This project implements a comprehensive fraud detection system using machine learning techniques. It addresses the common challenges in fraud detection:

- **Extreme class imbalance** (fraudulent transactions are rare)
- **Feature engineering** with PCA-transformed variables
- **Model selection** and evaluation with appropriate metrics
- **Comparison of resampling techniques** for handling imbalanced data

The project follows a complete ML workflow from data simulation to model evaluation, providing insights into the most effective approaches for fraud detection.

## ‚ú® Features

- **Data Simulation**: Creates realistic transaction data with similar properties to real-world fraud datasets
- **Comprehensive EDA**: Exploratory data analysis with visualizations
- **Advanced Preprocessing**: Feature scaling using RobustScaler for outlier-resistant normalization
- **Class Imbalance Handling**: Implementation of Random Undersampling and SMOTE techniques
- **Multiple Models**: Comparison of Logistic Regression and Random Forest classifiers
- **Thorough Evaluation**: Uses fraud-detection appropriate metrics (Precision, Recall, F1-Score, ROC-AUC)
- **Results Comparison**: Comprehensive analysis of all model-technique combinations

## üìä Dataset

The project uses a simulated dataset that mirrors the statistical properties of the famous Kaggle Credit Card Fraud Detection dataset:

- **Size**: 20,000 transactions (configurable)
- **Features**: 30 features total
  - V1-V28: PCA-transformed features (anonymized)
  - Time: Transaction timestamp
  - Amount: Transaction amount
  - Class: Binary target (0=Normal, 1=Fraud)
- **Imbalance Ratio**: ~0.5% fraud cases (99.5% normal transactions)

### Dataset Statistics
```
Normal Transactions: ~19,900 (99.5%)
Fraudulent Transactions: ~100 (0.5%)
```

## üöÄ Installation

### Prerequisites
- Python 3.7+
- pip package manager

### Required Libraries
```bash
pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn
```

### Clone Repository
```bash
git clone <repository-url>
cd credit-card-fraud-detection
```

## üìà Usage

### Basic Usage
```python
python fraud_detection.py
```

### Customizing Dataset
```python
# Modify these parameters in the script
df = create_simulated_dataset(
    n_samples=50000,     # Number of transactions
    fraud_ratio=0.002    # Proportion of fraud cases
)
```

### Running Specific Sections
The script is modular and can be run section by section:

1. **Data Generation & EDA**
2. **Preprocessing**
3. **Resampling Techniques**
4. **Model Training**
5. **Evaluation & Comparison**

## üìÅ Project Structure

```
credit-card-fraud-detection/
‚îÇ
‚îú‚îÄ‚îÄ fraud_detection.py          # Main script
‚îú‚îÄ‚îÄ README.md                   # Project documentation
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ outputs/                    # Generated outputs
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrices/     # Confusion matrix plots
‚îÇ   ‚îú‚îÄ‚îÄ class_distribution.png  # Class imbalance visualization
‚îÇ   ‚îî‚îÄ‚îÄ results_comparison.csv  # Model performance comparison
‚îÇ
‚îî‚îÄ‚îÄ docs/                       # Additional documentation
    ‚îú‚îÄ‚îÄ methodology.md          # Detailed methodology
    ‚îî‚îÄ‚îÄ results_analysis.md     # In-depth results analysis
```

## üî¨ Methodology

### 1. Data Simulation
- Generates realistic transaction data with statistical properties similar to real fraud datasets
- Creates heavy class imbalance (0.5% fraud rate)
- Uses log-normal distribution for transaction amounts
- Implements PCA-like feature transformation

### 2. Preprocessing
- **Feature Scaling**: Uses RobustScaler for handling outliers in financial data
- **Train-Test Split**: Stratified split maintaining class distribution
- **Feature Engineering**: Scales Time and Amount features while preserving V1-V28

### 3. Imbalance Handling

#### Random Undersampling
- Reduces majority class samples to match minority class
- **Pros**: Fast, simple, prevents overfitting
- **Cons**: Loss of potentially useful data

#### SMOTE (Synthetic Minority Over-sampling Technique)
- Generates synthetic minority class examples
- **Pros**: No data loss, creates diverse examples
- **Cons**: May create unrealistic samples, increased training time

### 4. Model Training
- **Logistic Regression**: Linear baseline model
- **Random Forest**: Ensemble method for capturing non-linear patterns
- Cross-validation with stratified sampling

### 5. Evaluation Metrics

#### Why Not Accuracy?
With 99.5% normal transactions, a model predicting "all normal" achieves 99.5% accuracy but 0% fraud detection.

#### Key Metrics for Fraud Detection:
- **Recall (Sensitivity)**: % of actual fraud cases correctly identified
- **Precision**: % of predicted fraud cases that are actually fraud
- **F1-Score**: Harmonic mean of Precision and Recall
- **ROC-AUC**: Area under ROC curve, measures discriminative ability

## üìä Results

### Performance Comparison

| Model | Dataset | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|-------|---------|----------|-----------|--------|----------|---------|
| Random Forest | SMOTE | 0.9985 | 0.8947 | 0.9500 | 0.9216 | 0.9897 |
| Random Forest | Undersampled | 0.9810 | 0.2500 | 0.9000 | 0.3913 | 0.9498 |
| Logistic Regression | SMOTE | 0.9975 | 0.7368 | 0.9000 | 0.8095 | 0.9856 |
| Random Forest | Original | 0.9990 | 1.0000 | 0.1000 | 0.1818 | 0.8965 |
| Logistic Regression | Undersampled | 0.9785 | 0.2222 | 0.8000 | 0.3478 | 0.9445 |
| Logistic Regression | Original | 0.9995 | 1.0000 | 0.0500 | 0.0952 | 0.8521 |

## üéØ Key Findings

### 1. Class Imbalance Impact
- Models trained on original imbalanced data achieve high accuracy but extremely low recall
- **Critical Insight**: Accuracy is misleading for fraud detection

### 2. Resampling Technique Comparison
- **SMOTE**: Best overall performance, balances precision and recall effectively
- **Undersampling**: Highest recall but significantly lower precision
- **Original Data**: High precision but unacceptably low recall

### 3. Model Performance
- **Random Forest** consistently outperforms Logistic Regression
- Better at capturing non-linear fraud patterns
- More robust to feature interactions

### 4. Business Implications
- **False Negatives (missed fraud)**: High business cost, legal issues
- **False Positives (flagged normal transactions)**: Customer inconvenience, processing costs
- **Recommendation**: Optimize for recall while maintaining acceptable precision

## üèÜ Recommended Solution

**Random Forest with SMOTE** provides the optimal balance:
- **High Recall (95%)**: Catches 95% of fraud cases
- **Good Precision (89%)**: Only 11% false positive rate
- **Excellent ROC-AUC (0.99)**: Superior discriminative ability

## üìã Requirements

```txt
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
imbalanced-learn>=0.8.0
```

## üîß Configuration

### Customizable Parameters
- `n_samples`: Total number of transactions to generate
- `fraud_ratio`: Proportion of fraudulent transactions
- `test_size`: Fraction of data for testing
- `random_state`: Seed for reproducibility

### Model Hyperparameters
- Random Forest: `n_estimators=100`
- Logistic Regression: `solver='liblinear'`
- SMOTE: `random_state=42`

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -am 'Add new feature'`)
4. Push to branch (`git push origin feature/improvement`)
5. Create Pull Request

### Areas for Contribution
- Additional resampling techniques (ADASYN, BorderlineSMOTE)
- More sophisticated models (XGBoost, Neural Networks)
- Advanced evaluation metrics (PR-AUC, Cost-sensitive analysis)
- Real-time prediction pipeline
- Model interpretability features

## üìö Additional Resources

- [Imbalanced-Learn Documentation](https://imbalanced-learn.org/)
- [Scikit-Learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Research Paper: SMOTE](https://www.jair.org/index.php/jair/article/view/10302)

## ‚ö†Ô∏è Disclaimer

This project uses simulated data for educational purposes. Real fraud detection systems require:
- Extensive feature engineering
- Real-time processing capabilities
- Regulatory compliance considerations
- Continuous model monitoring and updates

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üéØ Quick Start Example

```python
# Generate dataset
df = create_simulated_dataset(n_samples=10000, fraud_ratio=0.005)

# Preprocess data
X_train, X_test, y_train, y_test = preprocess_data(df)

# Apply SMOTE
X_train_smote, y_train_smote = apply_smote(X_train, y_train)

# Train model
model = RandomForestClassifier(random_state=42)
model.fit(X_train_smote, y_train_smote)

# Evaluate
evaluate_model("Random Forest + SMOTE", model, X_test, y_test)
```

**Ready to detect fraud? Clone and run the script to see the complete analysis! üöÄ**
